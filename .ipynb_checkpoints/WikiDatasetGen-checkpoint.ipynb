{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './wiki_data/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-77c91469ad78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwiki_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./wiki_data/data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0marticle_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwiki_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './wiki_data/data'"
     ]
    }
   ],
   "source": [
    "wiki_files = os.listdir('./wiki_data/data')\n",
    "article_titles = [title[:-4] for title in wiki_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_wiki_documents = []\n",
    "tokenized_wiki_summaries = []\n",
    "wiki_documents = []\n",
    "wiki_summaries = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_summary(article_lines):\n",
    "    index = -1\n",
    "    summary_indices = []\n",
    "    for i in range(len(article_lines)):\n",
    "        if article_lines[i] == 'Contents\\n':\n",
    "            index = i\n",
    "            break\n",
    "            \n",
    "    summary = []\n",
    "    \n",
    "    while(len(article_lines[index].split(\" \"))) < 8 and index >= 0:\n",
    "        index -= 1\n",
    "    \n",
    "    summary_indices.append(index)\n",
    "    \n",
    "    while len(article_lines[index].split(\" \")) > 8 and index >= 0:\n",
    "        summary.insert(0, article_lines[index].strip())\n",
    "        index -= 1\n",
    "        \n",
    "    summary_indices.append(index)\n",
    "        \n",
    "    return summary, summary_indices[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wiki_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e8188298a9f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwiki_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./wiki_data/data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wiki_files' is not defined"
     ]
    }
   ],
   "source": [
    "for file in wiki_files:\n",
    "    lines = open('./wiki_data/data/' + file).readlines()\n",
    "    summary, summary_indices = parse_summary(lines)\n",
    "    lower_bound, upper_bound = summary_indices\n",
    "    \n",
    "    if len(summary) > 0:\n",
    "        titles.append(file)\n",
    "        \n",
    "        tokenized_wiki_summaries.append(summary)\n",
    "        wiki_summaries.append('. '.join(summary))\n",
    "\n",
    "        cleaned_lines = [lines[i].strip() for i in range(len(lines)) if lines[i].strip() != '' and (i < lower_bound or i > upper_bound)]\n",
    "        tokenized_wiki_documents.append(cleaned_lines)\n",
    "        wiki_documents.append('. '.join(cleaned_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Titles', 'Summaries', 'Tokenized Summaries'])\n",
    "df['Titles'] = pd.Series(titles)\n",
    "df['Summaries'] = pd.Series(wiki_summaries)\n",
    "df['Tokenized Summaries'] = pd.Series(tokenized_wiki_summaries)\n",
    "df.to_csv('wiki_summaries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(columns=['Titles', 'Documents', 'Tokenized Documents'])\n",
    "df_2['Titles'] = pd.Series(titles)\n",
    "df_2['Documents'] = pd.Series(wiki_documents)\n",
    "df_2['Tokenized Documents'] = pd.Series(tokenized_wiki_documents)\n",
    "df_2.to_csv('wiki_documents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_3 = pd.DataFrame(columns=['Titles', 'Summaries', 'Documents'])\n",
    "df_3['Titles'] = pd.Series(titles)\n",
    "df_3['Summaries'] = pd.Series(wiki_summaries)\n",
    "df_3['Documents'] = pd.Series(wiki_documents)\n",
    "df_3.to_csv('wiki_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
